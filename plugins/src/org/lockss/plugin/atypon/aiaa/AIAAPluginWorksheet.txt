---------------------GENERAL INFORMATION-----------------------------Name of publisher: American Institute of Aeronautics and Astronautics Publishing platform?:AtyponRT:RU:JIRA: PD-128 The analysis was done before this form existed. So this writeup is initially minimal but as a BaseAtypon child there is a huge amount of overlap. Documenting differences as they crop upPlugin name suggestion: (eg. PubNamePlugin) AIAAPlugin.xml	Clockss? [yes/no]:		noGLN? [yes/no]:			yesPLN? [and name thereof]: TDB information: Same as BaseAtypon    PARAMS - base_url,     PARAMS - journal_id, volume_name    ATTRS:Base url: (eg. http://www.pub-name.org/) http://arc.aiaa.org/Start URL(s): Same as BaseAtypon: http://arc.aiaa.org/lockss/<journal_id>/<volume_name>Is the permission page in a different location? If so, where? HTML content with permission statementon maifest pagePick 3 AUs that you are using for initial evaluation? Write down their defined parameters. Choose AUs across a variety of journals (if available) and years to get a broad view of the publisher.(eg. Journal ID = abc; Volume = 2003; base_url = http://www.baseau-blah.org, etc)a) b)c)-----------------------URL & SITE LAYOUT SECTION-----------------------Refetch Depth (default is 1)What is the needed depth to pick up any new articles? Is this consistent for the site(s) layout? Does the publisher add items on a per-article basis or only on a per-issue basis?(explanatory examples - delete this when writing up analysis)   If the start_url is a manifest page for an entire volume and has links for the issues in that volume, then a refetch depth of 1 would refetch   anything on that first level, including any new issues added to the volume since the previous crawl.  But it would not fetch any new articles  added to an existing issue table of contents. With a refetch depth of 2 you would go on to each issue listed on the manifest page and if they  are a table of contents with links to each article, you would see and fetch any newly added article links.     Crawl rules & Content Layout(from earlier analysis)Each journal has a short name, referred to as the journal_id, which is part of the URL and therefore a configurable parameter.A regular end-user does not have access to a volume level page.  They can access a journal archive TOC at <base>/loi/<journal_id> which lists all the issues in groups of years.  They can click on any issue to get a TOC for that issue.LOCKSS has a special volume level page (manifest) that lives at     <base>/lockss/<journal_id>/<vol>    it seems to work whether you put nothing, /, /ndex.html or /index.html (and even an invalid issue#)This manifest page lists the issues for a particular year and each one takes you to the same issue TOC page that a user would get going off the archive issue list.An issue TOC lives at:    <base>/toc/<journal_id>/<issue> (with or without end slash)An issue TOC lists each article in the issue. Each one hascitation link : <base>/doi/abs/<2partdoi>(leads to an html page with the title & authors and possibly an image of the first page and it includes links to the PDF and PDFPlus versions in the header.pdf link: <base>/doi/pdf/<2partdoi>pdfplus link: <base/doi/pdfplug/<2partdoi>NOTE: There is no indication of year, volume or journal in the article's URLsThe issue TOC also lists author links with each article but these links just cause a search result for all articles written by the same author and therefore shouldn't be included in the crawl.NOTE - there is some generic publisher stuff under<base_url>/na101/home/literatum/publisher/aiaa/....--------------------------URL NORMALIZATION--------------------------------------------- #BLAH is sometimes added at the end but anchors are automatically noramlized off URLs Standard BaseAtypon URL Normalization to handle downloadCitation URLs, cookieSet, etc.----------------------HTML HASH FILTERING-----------------------------------------Standard BaseAtypon hash filtering with the addition of the following needed:   left sidebar   spaceholder for ads-------------------HTML CRAWL FILTERING----------------------------------------BaseAtypon seems adequate-----------------------PDF FILTER--------------------------------------------AIAA was complicated. They were generating PDFs that included a 'cited by' section which changed over time. Thib wrote a special pdf filter to handle this. -----------------------METADATA EXTRACTION--------------------------------------This is also unique for AIAA relative to BaseAtypon. The <meta> tags are available on the html article pageURLs exist for a citation download page, but the links aren't extractable by the standard JsoupHtmlLinkExtractor as they are for all the other Base Atypon children.In this case we need a custom AIAAHtmlLinkExtractor that extends the JsoupHtmlLinkExtractor and registersa different extractor for handling <a> tags.  Whent the <a> tag looks like this:  <a href="javascript:submitArticles(document.frmAs, 'action/showCitFormats', .....> </a>  we use the srcUrl to pick up the doi information and create a link likethis:  <base_url>action/showCitFormats?doi=xx.xxx/yyyyyy         in all other cases we fall back to the standard Jsoup link extractor.