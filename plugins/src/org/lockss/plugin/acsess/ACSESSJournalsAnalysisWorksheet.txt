-------------------INSTRUCTIONS-------------------------------------
Make a local copy of this file for each new plugin. 
Change its name to match the name of the plugin XML file, but with 
the .txt suffix. As you do your site analysis for the new plugin, 
follow along in this worksheet, filling in the answer to questions. 
Cut and paste specific URLs to support your notes and to allow 
subsequent readers to understand your analysis.

---------------------GENERAL INFORMATION----------------------------
Name of publisher: Alliance of Crop, Soil, and Environmental Science Societies

Publishing platform: custom

RT: https://support.lockss.org/Ticket/Display.html?id=5462

RU: 

JIRA: PD-48

Plugin name suggestion: 
* org.lockss.plugin.acsess.ACSESSJournalsPlugin
* org.lockss.plugin.acsess.ClockssACSESSJournalsPlugin

Clockss? [yes/no]: yes
GLN? [yes/no]: yes			
PLN? [and name thereof]: unknown 

TDB information:
    PARAMS - global
    PARAMS - journal specific
    ATTRS:

* base_url: https://dl.sciencesocieties.org/
* journal_id: aj
* volume_name: 103

Start URL(s):
* https://dl.sciencesocieties.org/publications/aj/tocs/103

Is the permission page in a different location? If so, where?
* the manifest page does not have permission statement
https://dl.sciencesocieties.org/publications/aj/tocs/103
* the permission statement is embedded in comments within the issue pages
https://dl.sciencesocieties.org/publications/aj/tocs/103/1

How does the permission statement work? 
* the permission statement is embedded in comments within the issue page
https://dl.sciencesocieties.org/publications/aj/tocs/103/1
<!-- LOCKSS system has permission to collect, preserve, and serve this Archival Unit CLOCKSS system has permission to ingest, preserve, and serve this Archival Unit -->

Pick 3 AUs that you are using for initial evaluation? Write down 
their defined parameters. 
Choose AUs across a variety of journals (if available) and years to 
get a broad view of the publisher.
(eg. Journal ID = abc; Volume = 2003; base_url = http://www.baseau-
blah.org, etc)

a) Agronomy Journal
   BASE_URL = https://dl.sciencesocieties.org/publications/
   JID = aj
   VOL = 106
   toc: https://dl.sciencesocieties.org/publications/aj/tocs/106/4
b) Crops & Soils
   BASE_URL = https://dl.sciencesocieties.org/publications/
   JID = cns
   VOL = 47
   toc: https://dl.sciencesocieties.org/publications/cns/tocs/47/3
c) Journal of Environmental Quality
   BASE_URL: https://dl.sciencesocieties.org/publications/
   JID: jeq
   VOL: 43
   toc: https://dl.sciencesocieties.org/publications/jeq/tocs/43/5
   
Article files:
- abs: https://dl.sciencesocieties.org/publications/aj/abstracts/106/1/57
- preview pdf (abs 2): https://dl.sciencesocieties.org/publications/cns/abstracts/47/1/20/preview
- html full text: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57
- pdf: https://dl.sciencesocieties.org/publications/aj/pdfs/106/1/57
- tables only: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=tables&wrapper=no
- figures only: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=figures&wrapper=no
- citation manager: https://dl.sciencesocieties.org/publications/citation-manager/prev/zt/aj/106/1/57
                    https://dl.sciencesocieties.org/publications/citation-manager/prev/zt/cns/47/1/12
- EndNote: https://dl.sciencesocieties.org/publications/citation-manager/down/en/aj/106/5/1677
- ProCite Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/pc/aj/106/5/1677
- Zotero Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/zt/aj/106/5/1677
- MARC: https://dl.sciencesocieties.org/publications/citation-manager/down/marc/aj/106/5/1677
- RefWorks: https://dl.sciencesocieties.org/publications/citation-manager/down/refworks/aj/106/5/1677
                    
-----------------------URL & SITE LAYOUT SECTION--------------------
Refetch Depth: 2
* the start url points to issue tocs and issu tocs point to articles 

Crawl rules & Content Layout
Is there a predictable URL pattern specific to each type of 
page/content? 
Below is a list of possible pages and types of content. This site 
will probably only contain a subset. Examine the AUs you chose above 
and note which items are applicable and give one or more URL 
examples for each that exists. If you can generalize to a pattern 
(eg. <base_url>/<toc/<journal_id>/<volume_name>/### ) then do so.

Article files:
- abs: https://dl.sciencesocieties.org/publications/aj/abstracts/106/1/57
- preview pdf (abs 2): https://dl.sciencesocieties.org/publications/cns/abstracts/47/1/20/preview
- html full text: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57
- pdf: https://dl.sciencesocieties.org/publications/aj/pdfs/106/1/57
- tables only: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=tables&wrapper=no
- figures only: https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=figures&wrapper=no
- citation manager: https://dl.sciencesocieties.org/publications/citation-manager/prev/zt/aj/106/1/57
                    https://dl.sciencesocieties.org/publications/citation-manager/prev/zt/cns/47/1/12
- EndNote: https://dl.sciencesocieties.org/publications/citation-manager/down/en/aj/106/5/1677
- ProCite Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/pc/aj/106/5/1677
- Zotero Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/zt/aj/106/5/1677
- MARC: https://dl.sciencesocieties.org/publications/citation-manager/down/marc/aj/106/5/1677
- RefWorks: https://dl.sciencesocieties.org/publications/citation-manager/down/refworks/aj/106/5/1677

Audio or Video?
* not found

Images, Figures & Tables
These items may exist in several formats, locations and with 
multiple access options.  First locate an 
article that includes images/figures/tables. If there is a full text 
html option, start there. Find an 
embedded image (figure, table) and note the following, giving URL 
examples for each.

** Figures/images are stored at URLs like this:
https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=tables&wrapper=no
https://dl.sciencesocieties.org/publications/aj/articles/106/1/57?show-t-f=figures&wrapper=no

DOI pattern
If this publisher uses DOIs, they may follow a pattern. It can be 
helpful to know what the 
pattern is. Give 3 examples of DOIs for this publisher including 
both parts (eg 101234/Blah_xxx124Is1)
* doi pattern not used

Other? Any other content specific to an article that wasn't listed 
above?? Give examples.

Addition Links to Include/Exclude
Now go back to both an issue table of contents page (or equivalent) 
AND an article html page and look at 
all the links on this page. This is easiest to do in firefox --> 
Page Info [Links tab].  
Scan all the links and note items that might need to be explicitly 
included or excluded 
(that wouldn't be under normal paths). If in doubt, just add an 
example URL in here.

Links to consider excluding
  underneath <base_url>, but includes something general, such as 
author info, citedby, servlet, searchId, etc
  javascript or style sheet links that seem to have a name that 
might be automatically generated (includes 
  date or hash string in the name, eg. 
<base_url>/cssJawr/N1854254985/style.css or 
LEKEJEEHEJ334449595.css).
  * <base_url>+
    https://dfzljdn9uc3pi.cloudfront.net/2013/images/
    https://d3amtssd1tejdt.cloudfront.net/2013/images/
    https://d2pdyyx74uypu5.cloudfront.net/2013/images/
    <base_url>/user/
    <base_url>/(articles|preprints)/[0-9]+/(author|editor)-[0-9]+
  
Links to consider including
  not underneath <base_url>, but looks specific to article content, 
such as images that live under a different base  
  underneath <base_url> and contains thins like showSupplements, 
showImage, downloadCitation)
  * files under these hosts:
    https://dfzljdn9uc3pi.cloudfront.net/2013/
    https://d3amtssd1tejdt.cloudfront.net/2013/
    https://d2pdyyx74uypu5.cloudfront.net/2013/ 
    
Does this site use automatically generated content?? 
View the page source for an article html page and look for something 
in the <head> section that looks like:
   __viewstate.X29DKTUELDKDHFLDKDN...
   __eventstate.KDIEJTEJSDODIJGJEKE...
  These types of items are generated by ASP and will change with 
each viewing of the page.  Please note the URL.
* __viewstate and __eventstate not found
* Css urls have trailing "?D"
<link type="text/css" rel="stylesheet" media="all" href="/modules/node/node.css?D" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/defaults.css?D" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/system.css?D" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/system-menus.css?D" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/user/user.css?D" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/all/modules/cck/theme/content-module.css?D" />

Notes
Anything else that you think the plugin writer needs to be aware of 
in terms of URL layout.

--------------------------URL NORMALIZATION-------------------------
As you click around from article to article or issue TOC are you 
getting arguments on the end of 
your URLs that are likely unnecessary.  Arguments are those items 
that follow a ? and may be 
separated with &.  Arguments that are necessary to identify the page 
usually look like this:
  ?showItem=<identifier>&format=pdf
whereas arguments that might be unnecessary might look like this
  ?rss=13&prev_item=333kfkfkfjk&lang=3n
These arguments might be keeping track of browsing history or date 
or language. You can test whether the 
arguments are needed by re-entering the URL without the arguments 
and seeing if you get the same page.
Give examples of URLs with arguments that we might need to remove. 
(eg. <full_url>?cookieSet=1 or <full_url>?prevSearch=3)

* There are multile ris files. We will collect both, but will use ProCite Ris
to extract metadata.  So urlnormalize Zotero to ProCite Ris.
  ProCite Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/pc/aj/106/5/1677
  Zotero Ris: https://dl.sciencesocieties.org/publications/citation-manager/down/zt/aj/106/5/1677

----------------------HTML HASH FILTERING---------------------------
Look at several types of html pages and look for types of items that 
are time or viewer dependent. 
These items will need to get hashed out. The plugin writer will need 
to go in to the page source 
to figure out how to remove the items, but you can identify which 
elements likely need to be removed.  
Here are suggestions for the type of things to look for. Make a note 
of the type of items you find 
and why you think they will need removal.  Give any URLs necessary 
to find the items you mention.

 ------Look for these sorts of things. Remove this list and replace 
it with what you find---------
  Name and/or logo of subscriber institution
  Login identity in shopping cart area
  Copyright on page showing year
  Cited by section 
  Issue link which points to current issue
  Product price listing
  Footer section including adds or date
  Related content or related article search
  Impact factor or viewing count
  Session history

And if you view the page source (firefox -> Page Source) look for 
the following:
<script/> tags with subscriber information, dates, or <!-- ... --> 
comment pairs that includes creation or modification date
sfxlink javascript commands

Anything else you think might need to be removed from hashing??

* include nodes:
- links from manifest page
        // toc - content
        // <div class="acsMarkLogicWrapper">
        HtmlNodeFilters.tagWithAttribute("div", "class", "acsMarkLogicWrapper"),        
        // abs, full - content block
        // <div id="content-block"
        HtmlNodeFilters.tagWithAttribute("div", "id", "content-block"),
        // tables-only - tables
        // <div class="table-expansion"
        HtmlNodeFilters.tagWithAttribute("div", "class", "table-expansion"),
        // figures-only - images
        // <div class="fig-expansion"
        HtmlNodeFilters.tagWithAttribute("div", "class", "fig-expansion"),

* exclude nodes:
        HtmlNodeFilters.tag("script"),
        //filter out comments
        HtmlNodeFilters.comment(),
        // toc - links to facebook and twitter near footer
        // <div style="display: block; margin: 10px 0px; clear: both;" class="noPrint">
        HtmlNodeFilters.tagWithAttributeRegex("div", "class", "noPrint"),  
        // abs, full - all left column except Citation Mgr (download citations)
        // <div class="content-box" id="article-cb-main">
        //   <a href="/publications/citation-manager/prev/zt/aj/106/5/1574">»Citation</a></div>
        HtmlNodeFilters.allExceptSubtree(
           HtmlNodeFilters.tagWithAttributeRegex("div", "id", "article-cb-main"),
             HtmlNodeFilters.tagWithAttributeRegex(
                    "a", "href", "/publications/citation-manager/")), 

----------------------XML HASH FILTERING---------------------------

-------------------HTML CRAWL FILTERING-----------------------------
If the URL pattern for articles is non-deterministic (that is, it 
doesn't contain volume name,  year, journal 
id specific information) then there is no way to know which 
journal/issue/volume an article is from. 
 deterministic URL: <base_url>/content/vol24/iss1/art1.pdf
 non-deterministic URL: <base_url/content/doi/pdf/11134/myartdoi12
which makes it very possible to crawl to content not from the 
original AU. If this is not the case, 
write "not applicable" or if it is, look for likely places where 
this could happen, such as those 
listed below. If you find some, please provide the URL for the page 
where you saw them.

* no need for crawl filter since the url is deterministic with journal id,
volume name and issue number:
https://dl.sciencesocieties.org/publications/aj/abstracts/106/1/57

 ------Look for these sorts of things. Remove this list and replace 
it with what you find---------
  Cited By Section - a link or section of links which point to 
  articles that reference this article
  Corrigendum or Article Correction links
  Related Content or Related Articles
  Original Article (pointing back from a corrected article to the 
  original)
  Prev Issue/massNext Issue links
  Prev Article/Next Article links (sometimes these dead end at the 
  ends of an issue, sometimes not)

* Article urls are non-deterministic: https://peerj.com/articles/46/
  However currently only 2013 content exists, it's too soon to tell 
  whether or not a crawl filter is needed.  We wait until the publisher adds 
  2014 content then revisit.
  
-----------------------LINK EXTRACTOR-------------------------------  
Link extractor might not needed from visual verification.  Tables and 
figures expand within the article full text html.  But will verify again
once able to crawl when permission statements are in place.

* probably no need for link extractor. will determine once able to crawl.

-----------------------PDF FILTER-----------------------------------
Some PDF files change every time they're viewed and will require a 
PDF filter. Download a PDF file of an article and view it. Does it contain an 
obvious watermark with date downloaded or some other time/viewer specific 
information? In Acrobat viewer look at the properties of the file. Is the date 
today's date? If so it's likely to be generated on the fly. If so, note 
the URL of the PDF you downloaded.

Now download the same PDF file a second time from a different 
browser (to ensure you're not getting cached version)

In a terminal window go to the directory that contain these two 
different versions of the same PDF file and run:
%diff -a pdf_version1.pdf pdf_version2.pdf
If there is a difference note that here and give the URL to the URL 
you tested.

* no need for pdf filter - downloaded pdfs from different days and "diff -a"
yields no differences.
https://dl.sciencesocieties.org/publications/cns/pdfs/47/1/22
https://dl.sciencesocieties.org/publications/aj/pdfs/103/1/169
https://dl.sciencesocieties.org/publications/jeq/pdfs/43/1/1
  
-----------------------METADATA EXTRACTION--------------------------
Metadata is provided in a variety of ways depending on the 
publisher. 
For example, Atypon plugins usually provide metadata in <meta.../> 
tags embedded in the html of 
an abstract and/or full text html page.  This only concerns article 
pages, not TOC pages.  
See if this is the case. Go to an article abstract or html page and 
do two things:

View the page info (firefox -> Page Info [General]). 
You should see a listing of metadata,  with names  such as dc.Title, 
dc. Creator, author, content_publisher, and then a value.

View the page source and search for the following "<meta" 
there should be about as many of these as there were items listed on 
the General Page Info page.

Other ways a publisher might provide metadata (if not as above) is 
as a downloadable citation file 
(ris, endnote, bibtex, etc). If so, please provide the format 
options and some examples for download.  

Some publishers don't provide explicit metadata and we need to parse 
the source html for basic information. Is that the case?

*ris -  * ?? SN is empty - what to do ??
* Multiple ris files: ProCite and Zotero. Urlnormalize Zotero ris to Procite ris.
So ProCite ris will be used for metadata extraction.
* Abstract and full text html also have metadata, so there will also be
an html metadata extractor to fall back if ris files are missing.


