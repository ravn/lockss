---------------------GENERAL INFORMATION-----------------------------Name of publisher: Tangram Edizione ScientifichePublishing platform?:RT:5010RU:4522Is this triggered content (no longer available from publisher)? How is this content delivered to us?Pull (we take it from the publisher site)? NOPush (the publisher uploads it to our ftp site)? YES    Schedule: on their own schedule    Do they deliver only incremental content or may there be repeat content:Plugin name suggestion: (eg. PubNamePlugin) ClockssTangramEdizioniScientificheSourcePuginClockss? [yes/no]:		YESGLN? [yes/no]:			PLN? [and name thereof]:Does this content represent Books? YESJournals? NOOther?TDB information - same as all clockss source chidren    PARAMS - global; base_url    PARAMS - journal specific; year_name    ATTRS:Base url: TBD but probably http://clockss-ingest.lockss.org/sourcefiles/tangram-released/ Where will we be serving the content from?:Is there a smaller development-only location for testing?:Start URL(s):How do we differentiate different AU's? For example, do we have year subdirectories below the base_url?Do we need to modify the existing directory structure under the base url for our purposes?   YES - somehow we got the publisher name wrong. It should be 'tangram', not 'tandem'... Types of content:For a particular AU (usually, a year's worth of content), what types of files may be included        *.pdf    *.epub    *.mobi    one of each type for each ebook    How are these file types used:            each book is available in 3 formats, one each of pdf, epub and mobiNaming convention if identifiable:                The filenames are a combination of author name plus unique number, including spaces,         eg: Brugiatelli 9788864580395.pdf                Note that one book has an inconsistent naming. The pdf is just the number,        9788864589978.pdf        is matched with Aquila_ebook.epub, and Aquila_ebook_mobi.mobi        We should consider changing this to be consistent for the purposes of the pluginIs there anything in the AU directory that should NOT be collected?    *.md5sum if they are included in the symlink treeNotes: Anything else worth noting about the source content?----------------------SUBSTANCE DEFINITION--------------------------------------Which files in a directory define substance?    eg: *.pdf, but not *.xml        For our purposes, we should collect all the formats but I would argue that     for the moment, based on the available tools, we need a *.pdf to have    viewable substance.    ------------------------ARTICLE ITERATION---------------------------------------Given the file types that may be provided for content, what is the map for contenttype to article target:        I will add the mobi and epub targets in to the local plugin to start so that    we can collect these formats in the ArticleFiles structure but we also need    to add these to the daemon for future general use.        -----------------------METADATA EXTRACTION--------------------------------------How is the publisher providing metadata for the content? We do not want to ingest sourcethat does not have accessible metadata. Scraping information out of a PDF file is not sufficient.Does the publisher provide XML files with metadata?    The publisher has not provided metadata and we need to request it. From the RT    it looks like we already did and they agreed to it, but it hasn't been delivered yet.          